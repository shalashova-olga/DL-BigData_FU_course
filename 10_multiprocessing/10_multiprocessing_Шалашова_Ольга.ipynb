{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDNR6prWHQQO"
   },
   "source": [
    "# Параллельные вычисления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, ast, time, os\n",
    "from typing import Dict, Tuple, Iterable, List\n",
    "from multiprocessing import Process, Queue, cpu_count\n",
    "\n",
    "try:\n",
    "    from openpyxl import load_workbook  # Для потокового чтения XLSX\n",
    "except Exception:\n",
    "    load_workbook = None  # Если пакет не установлен, остаётся поддержка только CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wdt-PAuHQQS"
   },
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 10: Параллельные вычисления\n",
    "* https://docs.python.org/3/library/multiprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmNnj0u2HQQS"
   },
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1Y7lmZuHQQT"
   },
   "source": [
    "1. Посчитайте, сколько раз встречается каждый из символов (заглавные и строчные символы не различаются) в файле `Dostoevskiy Fedor. Prestuplenie i nakazanie - BooksCafe.Net.txt` и в файле `Dostoevskiy Fedor. Igrok - BooksCafe.Net.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 17\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from typing import Dict\n",
    "import os\n",
    "\n",
    "def count_chars_in_file(file_path: str) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Подсчитать, сколько раз встречается каждый символ в файле.\n",
    "    Регистр игнорируем. Возвращает словарь {символ: количество}.\n",
    "    \"\"\"\n",
    "    char_counts = Counter()\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            char_counts.update(line.lower())\n",
    "    # можно убрать перевод строки, если не нужен\n",
    "    if \"\\n\" in char_counts:\n",
    "        del char_counts[\"\\n\"]\n",
    "    return dict(char_counts)\n",
    "\n",
    "\n",
    "file1 = \"Dostoevskiy Fedor. Prestuplenie i nakazanie - BooksCafe.Net.txt\"\n",
    "file2 = \"Dostoevskiy Fedor. Igrok - BooksCafe.Net.txt\"\n",
    "c1 = count_chars_in_file(file1)\n",
    "c2 = count_chars_in_file(file2)\n",
    "print(len(c1), len(c2)) #количество символов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ly2URoTFHQQT"
   },
   "source": [
    "2. Решить задачу 1, распараллелив вычисления с помощью модуля `multiprocessing`. Для обработки каждого файла создать свой собственный процесс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Dostoevskiy Fedor. Prestuplenie i nakazanie - BooksCafe.Net.txt', 'Dostoevskiy Fedor. Igrok - BooksCafe.Net.txt'])\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from typing import Dict, List\n",
    "from worker_functions import _worker_count\n",
    "\n",
    "def parallel_count_for_files(file_paths: List[str]) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Запускает отдельный процесс на каждый файл и собирает результаты\n",
    "    в multiprocessing.Manager().dict().\n",
    "    \"\"\"\n",
    "    with mp.Manager() as manager: # создаёт менеджер для разделяемых объектов между процессами\n",
    "        result = manager.dict() # доступный из всех процессов\n",
    "        procs = []\n",
    "        for fp in file_paths:\n",
    "            p = mp.Process(target=_worker_count, args=(fp, result, os.path.basename(fp))) #создаёт новый процесс(функция для выполнения\n",
    "            p.start()\n",
    "            procs.append(p)\n",
    "        for p in procs:\n",
    "            p.join() #ждём завершения каждого процесса\n",
    "        return dict(result)\n",
    "\n",
    "\n",
    "files = [file1, file2]\n",
    "res = parallel_count_for_files(files)\n",
    "print(res.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rr7lHbiuHQQT"
   },
   "source": [
    "## Лабораторная работа 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vmc6TxQjHQQT"
   },
   "source": [
    "1. Разбейте файл `recipes_full.csv` на несколько (например, 8) примерно одинаковых по объему файлов c названиями `id_tag_nsteps_*.csv`. Каждый файл содержит 3 столбца: `id`, `tag` и `n_steps`, разделенных символом `;`. Для разбора строк используйте `csv.reader`.\n",
    "\n",
    "__Важно__: вы не можете загружать в память весь файл сразу. Посмотреть на первые несколько строк файла вы можете, написав код, который считывает эти строки.\n",
    "\n",
    "Подсказка: примерное кол-во строк в файле - 2.3 млн.\n",
    "\n",
    "```\n",
    "id;tag;n_steps\n",
    "137739;60-minutes-or-less;11\n",
    "137739;time-to-make;11\n",
    "137739;course;11\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA_PATH = Path('recipes_full.csv')\n",
    "OUT_DIR = Path('results/')\n",
    "\n",
    "N_PARTS = 8\n",
    "\n",
    "DELIM = ';'\n",
    "\n",
    "PART_PREFIX = 'id_tag_nsteps_'\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_recipes_unified(path: Path):\n",
    "    #{'id': int, 'n_steps': int, 'tags': list[str]}\n",
    "    with open(path, 'r', encoding='utf-8-sig') as f:\n",
    "        #\n",
    "        reader = csv.reader(f) \n",
    "        header = next(reader)\n",
    "        \n",
    "        # Находим индексы колонок\n",
    "        idx = {name.lower(): i for i, name in enumerate(header)}\n",
    "        i_id = idx['id']\n",
    "        i_steps = idx['n_steps']\n",
    "        i_tags = idx['tags']\n",
    "        \n",
    "        for cols in reader:\n",
    "            rid = int(cols[i_id])\n",
    "            n_steps = int(cols[i_steps])\n",
    "            tags = ast.literal_eval(cols[i_tags])\n",
    "            \n",
    "            yield {'id': rid, 'n_steps': n_steps, 'tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Созданы части: ['id_tag_nsteps_1.csv', 'id_tag_nsteps_2.csv', 'id_tag_nsteps_3.csv', 'id_tag_nsteps_4.csv', 'id_tag_nsteps_5.csv', 'id_tag_nsteps_6.csv', 'id_tag_nsteps_7.csv', 'id_tag_nsteps_8.csv']\n",
      "Размеры (байт): [38846621, 38860091, 38844895, 38853250, 38849311, 38854677, 38848220, 38845459]\n"
     ]
    }
   ],
   "source": [
    "def split_to_parts_id_tag_nsteps_unified(src_path: Path, out_dir: Path, n_parts: int = 8) -> List[Path]:\n",
    "    \"\"\"Читает источники (.xlsx или .csv) потоково и создаёт `n_parts` файлов\n",
    "    с колонками `id;tag;n_steps`. Заполнение частей идёт по схеме **round-robin** —\n",
    "    по очереди в каждый файл, чтобы они получались примерно одинакового размера,\n",
    "    даже если заранее неизвестно общее число строк.\n",
    "    \"\"\"\n",
    "    # Готовим выходные файлы и csv.writer'ы\n",
    "    out_paths = [out_dir / f\"{PART_PREFIX}{i+1}.csv\" for i in range(n_parts)]\n",
    "    writers, files = [], []\n",
    "    try:\n",
    "        for p in out_paths: # Открываем все 8 файлов одновременно\n",
    "            f = open(p, 'w', newline='', encoding='utf-8')\n",
    "            files.append(f)\n",
    "            w = csv.writer(f, delimiter=DELIM)\n",
    "            w.writerow(['id','tag','n_steps'])  # пишем заголовок\n",
    "            writers.append(w)\n",
    "\n",
    "        # Индекс текущего файла для round-robin (0..n_parts-1)\n",
    "        rr = 0\n",
    "\n",
    "        # Идём по рецептам и раскладываем пары (id, tag, n_steps)\n",
    "        for rec in iter_recipes_unified(src_path):\n",
    "            rid = rec['id']\n",
    "            n_steps = rec['n_steps']\n",
    "            tags = rec['tags'] or []\n",
    "            if rid is None or n_steps is None:\n",
    "                continue  # перестраховка: пропустить странную строку\n",
    "\n",
    "            for tag in tags:\n",
    "                if not tag:\n",
    "                    continue\n",
    "                t = str(tag).strip()\n",
    "                if not t:\n",
    "                    continue\n",
    "                # Записываем строку и переходим к следующему \n",
    "                writers[rr].writerow([rid, t, n_steps])\n",
    "                rr = (rr + 1) % n_parts #   определяет в какой файл идет запись \n",
    "    finally:\n",
    "        # Гарантированно закрываем все файлы (даже при исключениях)\n",
    "        for f in files:\n",
    "            try:\n",
    "                f.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return out_paths\n",
    "\n",
    "\n",
    "parts = split_to_parts_id_tag_nsteps_unified(DATA_PATH, OUT_DIR, N_PARTS)\n",
    "print('Созданы части:', [p.name for p in parts])\n",
    "print('Размеры (байт):', [p.stat().st_size for p in parts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_n9G1I0aHQQU"
   },
   "source": [
    "2. Напишите функцию, которая принимает на вход название файла, созданного в результате решения задачи 1, считает среднее значение количества шагов для каждого тэга и возвращает результат в виде словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример 10 тегов из id_tag_nsteps_1.csv :\n",
      "mexican -> 5.32\n",
      "ham-and-bean-soup -> 3.53\n",
      "quick-breads -> 5.02\n",
      "60-minutes-or-less -> 9.50\n",
      "dinner-party -> 8.22\n",
      "course -> 9.25\n",
      "chicken -> 7.26\n",
      "veal -> 3.61\n",
      "dips-summer -> 3.56\n",
      "bacon -> 4.00\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "def tag_stats_from_part(csv_path: Path) -> Dict[str, Tuple[int,int]]:\n",
    "    \"\"\"Считает промежуточные статистики по одному файлу-части:\n",
    "       возвращает словарь `tag -> (sum_steps накапливаем, count)`.\n",
    "       Такой формат удобен для последующего корректного объединения результатов.\n",
    "    \"\"\"\n",
    "    stats: Dict[str, Tuple[int,int]] = {}\n",
    "    with open(csv_path, 'r', encoding='utf-8', newline='') as f:\n",
    "        r = csv.reader(f, delimiter=DELIM)\n",
    "        next(r, None)  # пропускаем заголовок\n",
    "        for row in r:\n",
    "            if len(row) != 3:\n",
    "                continue\n",
    "            _rid, tag, n_steps = row\n",
    "            if not tag:\n",
    "                continue\n",
    "            try:\n",
    "                n = int(n_steps)\n",
    "            except Exception:\n",
    "                continue\n",
    "            # Накапливаем сумму шагов и количество вхождений для тега\n",
    "            s,c = stats.get(tag, (0,0))\n",
    "            stats[tag] = (s+n, c+1)\n",
    "    return stats\n",
    "\n",
    "def tag_means_from_part(csv_path: Path) -> Dict[str, float]:\n",
    "    \"\"\"Возвращает `tag -> среднее n_steps` для одного файла.\"\"\"\n",
    "    stats = tag_stats_from_part(csv_path)\n",
    "    return {t: (s / c) for t, (s, c) in stats.items() if c > 0}\n",
    "\n",
    "# Мини-проверка на первой части\n",
    "example = tag_means_from_part(parts[0])\n",
    "print('Пример 10 тегов из', parts[0].name, ':')\n",
    "for k in list(example.keys())[:10]:\n",
    "    print(k, f\"-> {example[k]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOG_CWtPHQQU"
   },
   "source": [
    "3. Напишите функцию, которая считает среднее значение количества шагов для каждого тэга по всем файлам, полученным в задаче 1, и возвращает результат в виде словаря. Не используйте параллельных вычислений. При реализации выделите функцию, которая объединяет результаты обработки отдельных файлов. Модифицируйте код из задачи 2 таким образом, чтобы иметь возможность получить результат, имея результаты обработки отдельных файлов. Определите, за какое время задача решается для всех файлов.\n",
    "\n",
    "\n",
    "читаем частичный результат по одному файлу как (суммы, количества) по тегам;\n",
    "объединяем частичные результаты из многих файлов;\n",
    "считаем средние;\n",
    "измеряем время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Последовательно: 8 файлов за 5.2589 с; тегов: 551\n",
      "Примеры 10 тегов:\n",
      "mexican -> 5.30\n",
      "ham-and-bean-soup -> 3.51\n",
      "quick-breads -> 5.06\n",
      "60-minutes-or-less -> 9.41\n",
      "dinner-party -> 8.23\n",
      "course -> 9.27\n",
      "chicken -> 7.33\n",
      "veal -> 3.68\n",
      "dips-summer -> 3.48\n",
      "bacon -> 4.11\n"
     ]
    }
   ],
   "source": [
    "def merge_tag_stats(dicts: Iterable[Dict[str, Tuple[int,int]]]) -> Dict[str, Tuple[int,int]]:\n",
    "    \"\"\"Складывает несколько `tag -> (sum, count)` в один словарь.\"\"\"\n",
    "    merged: Dict[str, Tuple[int,int]] = {}\n",
    "    for d in dicts:\n",
    "        for tag, (s, c) in d.items(): # берет результат предидущего файла и к нему прибавляет значения\n",
    "            S, C = merged.get(tag, (0, 0))\n",
    "            merged[tag] = (S + s, C + c)\n",
    "    return merged\n",
    "\n",
    "def sequential_all_means(files: List[Path]):\n",
    "    \"\"\"Последовательно обрабатывает все части и считает финальные средние по тегам.\"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    parts_stats = [tag_stats_from_part(p) for p in files]\n",
    "    merged = merge_tag_stats(parts_stats)\n",
    "    means = {t: (s / c) for t, (s, c) in merged.items() if c > 0}\n",
    "    dt = time.perf_counter() - t0\n",
    "    return means, dt\n",
    "\n",
    "means_seq, t_seq = sequential_all_means(parts)\n",
    "print(f'Последовательно: {len(parts)} файлов за {t_seq:.4f} с; тегов: {len(means_seq)}')\n",
    "print('Примеры 10 тегов:')\n",
    "for k in list(means_seq.keys())[:10]:\n",
    "    print(k, f\"-> {means_seq[k]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x3x5-47HQQU"
   },
   "source": [
    "4. Решите задачу 3, распараллелив вычисления с помощью модуля `multiprocessing`. Для обработки каждого файла создайте свой собственный процесс. Определите, за какое время задача решается для всех файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp(one-per-file): 8 файлов за 21.9336 с; тегов: 551\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue, cpu_count\n",
    "from worker_functions import worker_file_stats\n",
    "'''\n",
    "ОСНОВНОЙ ПРОЦЕСС:\n",
    "1. Создаём Queue()\n",
    "2. Запускаем 8 процессов - worker_file_stats\n",
    "РАБОЧИЕ ПРОЦЕССЫ (параллельно):q.put(результат1)...\n",
    "ОСНОВНОЙ ПРОЦЕСС:\n",
    "[q.get(), q.get(), q.get()...] ← ждёт 8 результатов\n",
    "'''\n",
    "\n",
    "\n",
    "def mp_one_proc_per_file(files: List[Path]):\n",
    "    \"\"\"Запускает по **отдельному процессу на каждый файл**.\n",
    "       Коммуникация через очередь: каждый процесс кладёт в неё словарь статистик.\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    q = Queue()\n",
    "    procs = []\n",
    "    for p in files:\n",
    "        pr = Process(target=worker_file_stats, args=(str(p), q)) #аргументы: путь к файлу и очередь\n",
    "        pr.start() #Процесс начинает выполнение НЕЗАВИСИМО от основного процесса\n",
    "        procs.append(pr)\n",
    "\n",
    "    # Забираем результаты от всех процессов\n",
    "    collected = [q.get() for _ in files]\n",
    "\n",
    "    # Дожидаемся завершения\n",
    "    for pr in procs:\n",
    "        pr.join() #гарантирует, что все процессы завершились корректно\n",
    "\n",
    "    merged = merge_tag_stats(collected)\n",
    "    means = {t: (s / c) for t, (s, c) in merged.items() if c > 0}\n",
    "    dt = time.perf_counter() - t0\n",
    "    return means, dt\n",
    "\n",
    "means_mp1, t_mp1 = mp_one_proc_per_file(parts)\n",
    "print(f'mp(one-per-file): {len(parts)} файлов за {t_mp1:.4f} с; тегов: {len(means_mp1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9ipTe-WHQQV"
   },
   "source": [
    "5. (*) Решите задачу 3, распараллелив вычисления с помощью модуля `multiprocessing`. Создайте фиксированное количество процессов (равное половине количества ядер на компь ютере). При помощи очереди передайте названия файлов для обработки процессам и при помощи другой очереди заберите от них ответы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp(fixed-workers): 8 файлов за 39.3828 с; тегов: 551\n",
      "Совпадение ключей: True\n"
     ]
    }
   ],
   "source": [
    "from worker_functions import worker_fixed\n",
    "\n",
    "'''\n",
    "ОСНОВНОЙ ПРОЦЕСС:\n",
    "1. Создаём 6 процесса-воркера\n",
    "2. Кладём 8 файлов в in_q: [f1, f2, f3, f4, f5, f6, f7, f8]\n",
    "3. Кладём 4 стоп слова: [None, None, None, None]\n",
    "\n",
    "ПРОЦЕССЫ-ВОРКЕРЫ:\n",
    "P1: in_q.get() → f1 → обработал → out_q.put(результат1)\n",
    "    in_q.get() → f7 → обработал → out_q.put(результат5)  \n",
    "    in_q.get() → None → break (завершился)\n",
    "и так далее\n",
    "ОСНОВНОЙ ПРОЦЕСС:\n",
    "out_q.get() × 8 → [результат1, результат2, ..., результат8]\n",
    "'''\n",
    "\n",
    "def mp_fixed_workers(files: List[Path], n_workers: int | None = None):\n",
    "    \"\"\"Запускает фиксированное число рабочих процессов (по умолчанию: половина ядер).\n",
    "       Задания подаются через очередь `in_q`, результаты собираются из `out_q`.\n",
    "    \"\"\"\n",
    "    if n_workers is None:\n",
    "        n_workers = max(1, cpu_count() // 2) #12/2\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    in_q, out_q = Queue(), Queue() # пути к файлам, для результатов\n",
    "\n",
    "    # Стартуем пул рабочих процессов\n",
    "    procs = [Process(target=worker_fixed, args=(in_q, out_q)) for _ in range(n_workers)] # создаем процессы которые на старте get\n",
    "    for pr in procs:\n",
    "        pr.start() # распределяем задания по процессам\n",
    "\n",
    "    # Подаём задания (пути) в очередь\n",
    "    for p in files:\n",
    "        in_q.put(str(p))\n",
    "\n",
    "    # Отправляем каждому процессу знак None — указание завершиться\n",
    "    for _ in procs:\n",
    "        in_q.put(None) \n",
    "\n",
    "    # Собираем результаты\n",
    "    collected = [out_q.get() for _ in files]\n",
    "\n",
    "    # Дожидаемся завершения всех процессов\n",
    "    for pr in procs:\n",
    "        pr.join()\n",
    "\n",
    "    merged = merge_tag_stats(collected)\n",
    "    means = {t: (s / c) for t, (s, c) in merged.items() if c > 0}\n",
    "    dt = time.perf_counter() - t0\n",
    "    return means, dt\n",
    "\n",
    "means_mp2, t_mp2 = mp_fixed_workers(parts)\n",
    "print(f'mp(fixed-workers): {len(parts)} файлов за {t_mp2:.4f} с; тегов: {len(means_mp2)}')\n",
    "print('Совпадение ключей:', set(means_seq.keys()) == set(means_mp1.keys()) == set(means_mp2.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Удаляем модуль из кеша, чтобы перезагрузить\n",
    "if 'worker_functions' in sys.modules:\n",
    "    del sys.modules['worker_functions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
