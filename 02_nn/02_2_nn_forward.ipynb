{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a564d5f",
   "metadata": {},
   "source": [
    "#  Forward pass\n",
    "\n",
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы: \n",
    "* Deep Learning with PyTorch (2020) Авторы: Eli Stevens, Luca Antiga, Thomas Viehmann \n",
    "* https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
    "* https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
    "* https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/\n",
    "* https://kidger.site/thoughts/jaxtyping/\n",
    "* https://github.com/patrick-kidger/torchtyping/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecd663",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b6ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtyping\n",
      "  Downloading torchtyping-0.1.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchtyping) (2.7.1)\n",
      "Collecting typeguard<3,>=2.11.1 (from torchtyping)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.0->torchtyping) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.0->torchtyping) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.0->torchtyping) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.0->torchtyping) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.0->torchtyping) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.0->torchtyping) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.0->torchtyping) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.7.0->torchtyping) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.7.0->torchtyping) (3.0.2)\n",
      "Downloading torchtyping-0.1.5-py3-none-any.whl (17 kB)\n",
      "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, torchtyping\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torchtyping]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torchtyping-0.1.5 typeguard-2.13.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7ad9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtyping import TensorType, patch_typeguard\n",
    "from typeguard import typechecked\n",
    "import torch as th\n",
    "import torch\n",
    "\n",
    "Scalar = TensorType[()]\n",
    "patch_typeguard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87d01a9",
   "metadata": {
    "id": "_2ArJn_nsdZC"
   },
   "source": [
    "1\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте нейрон с заданными весами `weights` и `bias`. Пропустите вектор `inputs` через нейрон и выведите результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc1b50d5",
   "metadata": {
    "id": "f4agkY9WqPwe"
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, n_features: int, bias: float):\n",
    "        # <создать атрибуты объекта weights и bias>\n",
    "        self.weights: TensorType[n_features] =  torch.ones(n_features)\n",
    "        self.bias: float = bias\n",
    "\n",
    "    def forward(self, inputs: TensorType[\"n_features\"]) -> Scalar:\n",
    "        result = th.dot(inputs, self.weights)\n",
    "        if self.bias is not None:\n",
    "            result += self.bias\n",
    "        return result# <реализовать логику нейрона>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60f299f7",
   "metadata": {
    "id": "HJRkSkHHsb7u"
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "inputs = th.tensor([1.0, 2.0, 3.0, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbc5e6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron = Neuron(4, True)\n",
    "neuron.forward(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e5fe51",
   "metadata": {
    "id": "B9kngE6Fxs9D"
   },
   "source": [
    "2\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию активации ReLU:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f4353f4e3e484130504049599d2e7b040793e1eb)\n",
    "\n",
    "Создайте матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверьте работоспособность функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4679f4e5",
   "metadata": {
    "id": "jZLvMRByxSTC"
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    @typechecked\n",
    "    def forward(self, inputs: TensorType[\"n_features\"]) -> TensorType[\"n_features\"]:\n",
    "        return th.maximum(inputs, th.tensor(0.0))# <реализовать логику ReLU>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a16748",
   "metadata": {
    "id": "EY-k3eEs0f7f"
   },
   "source": [
    "3\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию потерь MSE:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e)\n",
    "где $Y_i$ - правильный ответ для примера $i$, $\\hat{Y_i}$ - предсказание модели для примера $i$, $n$ - количество примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e046dfa6",
   "metadata": {
    "id": "f9-wdj5Tz-br"
   },
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    @typechecked\n",
    "    def forward(self, y_pred: TensorType[\"batch\"], y_true: TensorType[\"batch\"]) -> Scalar:\n",
    "        return th.mean((y_pred - y_true) **2)# <реализовать логику MSE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e686f8b8",
   "metadata": {
    "id": "NAyuDU9F1Vuz"
   },
   "outputs": [],
   "source": [
    "y_pred = th.tensor([1.0, 3.0, 5.0])\n",
    "y_true = th.tensor([2.0, 3.0, 4.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b6d63",
   "metadata": {},
   "source": [
    "## Задачи для самостоятельного решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e742b",
   "metadata": {
    "id": "0J2RM8f5wP33"
   },
   "source": [
    "### Cоздание полносвязных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe867c",
   "metadata": {
    "id": "OQ2OxH4_vBLu"
   },
   "source": [
    "<p class=\"task\" id=\"1\"></p>\n",
    "\n",
    "1\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте полносвязный слой из `n_neurons` нейронов с `n_features` весами у каждого нейрона (инициализируются из стандартного нормального распределения) и опциональным вектором смещения. \n",
    "\n",
    "$$y = xW^T + b$$\n",
    "\n",
    "Пропустите вектор `inputs` через слой и выведите результат. Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "680571a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, n_neurons: int, n_features: int, bias: bool = False) -> None:\n",
    "        self.weights: TensorType[n_features] =  th.randn(n_neurons, n_features)\n",
    "        self.bias: float = th.randn(n_neurons) if bias else None\n",
    "\n",
    "    def forward(self, inputs: TensorType[\"batch\", \"feats\"]) -> TensorType[\"batch\", \"n_neurons\"]:\n",
    "        output = th.matmul(inputs, self.weights.T)\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825fef2-0b73-4933-a0b2-9012f565a1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d674f8fe-0329-44a9-911f-44d8283dea29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7634, -5.1476,  4.0991, -0.7604])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = Linear(4, len(inputs), True)\n",
    "linear.forward(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad52a4f",
   "metadata": {
    "id": "IPG4UqL4wajI"
   },
   "source": [
    "<p class=\"task\" id=\"2\"></p>\n",
    "\n",
    "2\\. Используя решение предыдущей задачи, создайте 2 полносвязных слоя и пропустите тензор `inputs` последовательно через эти два слоя. Количество нейронов в первом слое выберите произвольно, количество нейронов во втором слое выберите так, чтобы результатом прогона являлась матрица `batch_size x 7`. \n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dde696cd-02dc-4db9-b57a-f479b87a88b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "выход первого слоя: tensor([[ 4.6278, -1.3499, -6.2242,  2.0020, -9.1487, -8.8083]])\n",
      "выход: tensor([[ -6.9187,   4.3071,  24.2933,  41.8108, -21.3752,  26.5358,  10.0904]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs = inputs.unsqueeze(0)  #TensorType[\"batch\", \"feats\"]\n",
    "\n",
    "n_features = 4\n",
    "n_neurons_1 = 6  \n",
    "linear1 = Linear(n_neurons_1, n_features, bias=True)\n",
    "\n",
    "\n",
    "output1 = linear1.forward(batch_inputs)\n",
    "print(f\"выход первого слоя: {output1}\")\n",
    "\n",
    "n_neurons_2 = 7  \n",
    "linear2 = Linear(n_neurons_2, n_neurons_1, bias=True)\n",
    "\n",
    "\n",
    "output2 = linear2.forward(output1)\n",
    "print(f\"выход: {output2}\")\n",
    "\n",
    "\n",
    "output2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f89bb8e",
   "metadata": {
    "id": "cRVH_2K7xTBC"
   },
   "source": [
    "### Создание функций активации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c912a6",
   "metadata": {
    "id": "puExCWiKyTtb"
   },
   "source": [
    "<p class=\"task\" id=\"3\"></p>\n",
    "\n",
    "3\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию активации softmax:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d7500d980c313da83e4117da701bf7c8f1982f5)\n",
    "\n",
    "$$\\overrightarrow{x} = (x_1, ..., x_J)$$\n",
    "\n",
    "Создайте матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверьте работоспособность функции активации. Строки матрицы трактовать как выходы линейного слоя некоторого классификатора для 4 различных примеров. Функция должна применяться переданной на вход матрице построчно.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "41ec4062",
   "metadata": {
    "id": "fXNcFlqqyKHl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "class Softmax:\n",
    "    def forward(self, inputs: TensorType[\"batch\", \"feats\"]) -> TensorType[\"batch\", \"feats\"]:\n",
    "        exp_inputs = th.exp(inputs-  th.max(inputs, dim=1, keepdim=True).values)\n",
    "        return exp_inputs / th.sum(exp_inputs, dim=1, keepdim=True)# <реализовать логику Softmax>\n",
    "\n",
    "softmax = Softmax()\n",
    "softmax_result = softmax.forward(th.randn(4, 3))\n",
    "print(softmax_result.size())\n",
    "print(th.sum(softmax_result, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c10f2103-9f7f-48be-a92c-33f7bfefb7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4249,  0.1640,  0.7527],\n",
       "        [-0.2598,  0.6996, -0.7397],\n",
       "        [ 0.8849, -0.1195, -0.4032],\n",
       "        [-0.1703,  0.1313, -0.6358]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.randn(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8acbae",
   "metadata": {
    "id": "vxVK2TYez_Ye"
   },
   "source": [
    "<p class=\"task\" id=\"4\"></p>\n",
    "\n",
    "4 Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию активации ELU:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/eb23becd37c3602c4838e53f532163279192e4fd)\n",
    "\n",
    "Создайте матрицу размера 4x3, заполненную числами из стандартного нормального распределения, и проверьте работоспособность функции активации.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "998b3675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 0.1083, -0.2983,  1.3293],\n",
      "        [ 1.5927,  0.6134,  2.1727],\n",
      "        [-0.1595,  0.1295,  1.3103],\n",
      "        [ 0.1431, -0.0638,  0.3363]])\n"
     ]
    }
   ],
   "source": [
    "class ELU:\n",
    "    def __init__(self, alpha: float) -> None:\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, inputs: TensorType[\"batch\", \"feats\"]) -> TensorType[\"batch\", \"feats\"]:\n",
    "        return th.where(inputs > 0, inputs, self.alpha * (th.exp(inputs) - 1))\n",
    "\n",
    "\n",
    "elu = ELU(0.5)\n",
    "elu_result = elu.forward(th.randn(4, 3))\n",
    "print(elu_result.size())\n",
    "print(elu_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02fb0d",
   "metadata": {
    "id": "0peh8r-20Pof"
   },
   "source": [
    "### Создание функции потерь"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bab7e56a",
   "metadata": {
    "id": "uaR7rILd1eWR"
   },
   "source": [
    "<p class=\"task\" id=\"5\"></p>\n",
    "\n",
    "5 Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию потерь CrossEntropyLoss:\n",
    "\n",
    "$$y_i = (y_{i,1},...,y_{i,k})$$ \n",
    "\n",
    "<img src=\"https://i.ibb.co/93gy1dN/Screenshot-9.png\" width=\"200\">\n",
    "\n",
    "$$ CrossEntropyLoss = \\frac{1}{n}\\sum_{i=1}^{n}{L_i}$$\n",
    "где $y_i$ - вектор правильных ответов для примера $i$, $\\hat{y_i}$ - вектор предсказаний модели для примера $i$; $k$ - количество классов, $n$ - количество примеров в батче.\n",
    "\n",
    "Создайте полносвязный слой с 2 нейронами и прогнать через него батч `inputs`. Полученный результат пропустите через функцию активации Softmax. Посчитайте значение функции потерь, трактуя вектор `y` как вектор правильных ответов.\n",
    "\n",
    "- [ ] Проверено на семинаре\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f683f102",
   "metadata": {
    "id": "hQl8pJsT3HcF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания (после softmax): tensor([[[0.9953, 0.9934],\n",
      "         [0.0047, 0.0066]]])\n",
      "Значение функции потерь: 2.681881904602051\n"
     ]
    }
   ],
   "source": [
    "inputs = th.tensor([\n",
    "    [1.0, 2.0, 3.0, 4.0],   \n",
    "    [1.0, 3.0, 2.0, 0.0]    \n",
    "])  \n",
    "\n",
    "y = th.tensor([\n",
    "    [0.0, 1.0], \n",
    "    [1.0, 0.0]  \n",
    "])  \n",
    "\n",
    "\n",
    "linear = Linear(n_neurons=2, n_features=4, bias=True)\n",
    "logits = linear.forward(inputs)  \n",
    "\n",
    "softmax_preds = softmax.forward(logits.unsqueeze(0))  \n",
    "\n",
    "loss = -th.sum(y * th.log(softmax_preds)) / y.shape[0]\n",
    "\n",
    "print(\"Предсказания (после softmax):\", softmax_preds)\n",
    "print(\"Значение функции потерь:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c82a1",
   "metadata": {
    "id": "fA6dbanf44_4"
   },
   "source": [
    "<p class=\"task\" id=\"6\"></p>\n",
    "\n",
    "6 Модифицируйте MSE, добавив L2-регуляризацию.\n",
    "\n",
    "$$MSE_R = MSE + \\lambda\\sum_{i=1}^{m}w_i^2$$\n",
    "\n",
    "где $\\lambda$ - коэффициент регуляризации; $w_i$ - веса модели.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b1f858a9",
   "metadata": {
    "id": "ADsZxD-h4_Os"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8063)\n"
     ]
    }
   ],
   "source": [
    "class MSERegularized:\n",
    "    def __init__(self, lambda_: float) -> None:\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def data_loss(\n",
    "            self, \n",
    "            y_pred: TensorType[\"batch\"], \n",
    "            y_true: TensorType[\"batch\"],\n",
    "    ) -> Scalar:\n",
    "        return th.mean((y_pred - y_true) **2)# <реализовать логику MSE>\n",
    "\n",
    "    def reg_loss(self, weights: TensorType[\"batch\", 1])  -> Scalar:\n",
    "        return th.sum(weights ** 2)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        y_pred: TensorType[\"batch\"], \n",
    "        y_true: TensorType[\"batch\"], \n",
    "        weights: TensorType[\"batch\", 1],\n",
    "    ) -> Scalar:\n",
    "        return self.data_loss(y_pred, y_true) + self.lambda_ * self.reg_loss(weights)\n",
    "\n",
    "\n",
    "\n",
    "mse_reg = MSERegularized(0.01)\n",
    "weights = th.randn(10, 1)\n",
    "print(mse_reg.forward(y_pred, y_true, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca3b24-5bd7-4696-8471-4d04b218d0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
